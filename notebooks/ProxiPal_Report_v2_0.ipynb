{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94ff0f10",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<div style=\"font-size:36px; font-weight:bold\">NfL IC-PLA Experiment Report</div>\n",
    "<br>\n",
    "<div style=\"font-size:14px; font-weight:bold\">Neurofilament Light Chain (NfL) Immuno-Complex Proximity Ligation Assay (Document v1.9), Ref: PxK 001 </div>\n",
    "<hr style=\"border: none; border-top: 3px solid black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a6b7e3",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "__Scope:__ This reporting template will analyse single experiments and is designed for users who must balance their research needs with data management for large studies. For a detailed explanation of the ProxiPal package, design choices, permission structures, and user templates refer to the ProxiPal manual. We provide a jupyter notebook, not a web-server, so that users can manage their own security.  \n",
    "\n",
    "__Features:__ While one report format is being maintained, flexibility is required to accomodate all users.  \n",
    "- Use the _\"Toggle Code Cells\"_ button to improve readability. Advanced users can modify display tables via code cells.\n",
    "- Check experimental data folders for requisite files  \n",
    "- Calculate and export files csv formats that respects users with different access privileges  \n",
    "- Interactive (Qgrid) tables permit sorting and filtering but cannot be saved. \n",
    "- Static (Pandas) tables are immutable and can be saved. To export to pdf or html, or to save notebook outputs with re-running the code cells, users should display pandas tables prior to saving their work.  \n",
    "- Sample identification let's admin users match experiment values with sample submission information.  \n",
    "- Batching let's admin users reprocess all experiments with the requisite files.  \n",
    "  \n",
    "<div style=\"font-size:16px; font-weight:bold; color:red\">Hit \"Run\" to initialise the report</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee792b8",
   "metadata": {},
   "source": [
    "#### Updates & bugfixes  \n",
    "Variables need to be described in the experiment conditions  \n",
    "Variables need to be shown on the report for each well  \n",
    "Variables need to be described for the standards reporting  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24de04da",
   "metadata": {
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, HTML, Javascript, clear_output, Image, Markdown\n",
    "\n",
    "\n",
    "class CodeToggler:\n",
    "    def __init__(self):\n",
    "        self.is_visible = True  # Track state\n",
    "        \n",
    "        # Improved JavaScript with state tracking and all cells handling\n",
    "        self.js_code = \"\"\"\n",
    "        var jupyterCodeToggler = {\n",
    "            isVisible: true,\n",
    "            \n",
    "            toggleCodeCells: function() {\n",
    "                // Get all input cells including those before the button\n",
    "                var codeCells = document.querySelectorAll('div.input');\n",
    "                var newDisplay = this.isVisible ? 'none' : 'block';\n",
    "                \n",
    "                // Update all cells\n",
    "                codeCells.forEach(function(cell) {\n",
    "                    cell.style.display = newDisplay;\n",
    "                });\n",
    "                \n",
    "                // Toggle state\n",
    "                this.isVisible = !this.isVisible;\n",
    "                \n",
    "                // Store state in localStorage for persistence\n",
    "                localStorage.setItem('jupyterCodeTogglerState', this.isVisible);\n",
    "            },\n",
    "            \n",
    "            initializeState: function() {\n",
    "                // Restore state from localStorage or default to visible\n",
    "                var savedState = localStorage.getItem('jupyterCodeTogglerState');\n",
    "                this.isVisible = savedState === null ? true : savedState === 'true';\n",
    "                \n",
    "                // Apply initial state\n",
    "                var codeCells = document.querySelectorAll('div.input');\n",
    "                var display = this.isVisible ? 'block' : 'none';\n",
    "                codeCells.forEach(function(cell) {\n",
    "                    cell.style.display = display;\n",
    "                });\n",
    "            }\n",
    "        };\n",
    "        \n",
    "        // Initialize state when the notebook loads\n",
    "        jupyterCodeToggler.initializeState();\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create and configure the button\n",
    "        self.button = widgets.Button(\n",
    "            description=\"Toggle Code Cells\",\n",
    "            layout=widgets.Layout(width='250px'),\n",
    "            tooltip=\"Click to show/hide code cells\"\n",
    "        )\n",
    "        \n",
    "        # Define the toggle function\n",
    "        def toggle_code_cells(button):\n",
    "            display(Javascript(\"jupyterCodeToggler.toggleCodeCells();\"))\n",
    "            self.is_visible = not self.is_visible\n",
    "            button.description = \"Hide Code Cells\" if self.is_visible else \"Show Code Cells\"\n",
    "            \n",
    "        # Bind the function to the button\n",
    "        self.button.on_click(toggle_code_cells)\n",
    "    \n",
    "    def initialize(self):\n",
    "        \"\"\"Initialize the toggler in the notebook\"\"\"\n",
    "        # First inject the JavaScript code\n",
    "        display(HTML(f\"<script>{self.js_code}</script>\"))\n",
    "        # Then display the button\n",
    "        display(self.button)\n",
    "\n",
    "# Create and initialize the toggler\n",
    "toggler = CodeToggler()\n",
    "toggler.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144c8848",
   "metadata": {},
   "source": [
    "<div style=\"font-size:24px; font-weight:bold\">Execution environment  </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b277d9ac",
   "metadata": {
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ProxiPal import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee13387d",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "# Data Folder Functions  \n",
    "The __/data__ folder is general access and where users should save their experiment files. Users can access csv outputs of all displayed tables from the relevant experiment's __/exports__ folder.\n",
    "\n",
    "## Review available experimental data  \n",
    "Use this table to confirm which experiments have the requisite files for an analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bc86cc",
   "metadata": {
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import qgrid\n",
    "\n",
    "# Check for an eds > txt export\n",
    "eds2txt_match_list, eds2txt_match_dict = find_matched_filenames(base_path, read_export = True)\n",
    "# Check for a csv file with the same name as the eds file\n",
    "eds2csv_match_list, eds2csv_match_dict = find_matched_filenames(base_path, native_format = '.eds', export_format = '.csv', read_export = True)\n",
    "# Review matched filenames\n",
    "df_pivot = review_matched_filenames(eds2txt_match_dict, eds2csv_match_dict)\n",
    "# Create a df_pivot without the path_key column for display purposes\n",
    "df_without_path_key = df_pivot.drop(columns=\"path_key\")\n",
    "\n",
    "# Define column options and definitions\n",
    "col_options = {'width': 100}\n",
    "col_defs = {\n",
    "    'index': {'width': col_options['width'] / 15},\n",
    "    'experiment': {'width': col_options['width'] / 1.3},\n",
    "    'eds filename': {'width': 3 * col_options['width']},\n",
    "    'txt': {'width': col_options['width'] / 4},\n",
    "    'csv': {'width': col_options['width'] / 4},\n",
    "    'analysis': {'width': col_options['width'] / 2.4},\n",
    "}\n",
    "\n",
    "# Grid options: disable addition and deletion of rows\n",
    "grid_options = {\n",
    "    'enableColumnReorder': True,\n",
    "    'enableTextSelectionOnCells': True,\n",
    "    'editable': False,\n",
    "    'autoEdit': False,\n",
    "    'explicitInitialization': True,\n",
    "    'maxVisibleRows': 15,\n",
    "    'minVisibleRows': 8,\n",
    "    'sortable': True,\n",
    "    'filterable': True,\n",
    "    'highlightSelectedCell': False,\n",
    "    'highlightSelectedRow': True\n",
    "}\n",
    "\n",
    "def display_qgrid_table_rev(button):\n",
    "    # Create qgrid widget\n",
    "    qgrid_widget = qgrid.show_grid(df_without_path_key, \n",
    "                                show_toolbar=False,  # disables toolbar\n",
    "                                grid_options=grid_options,  # pass grid options\n",
    "                                column_options=col_options, \n",
    "                                column_definitions=col_defs)\n",
    "    # Hide the index column\n",
    "    qgrid_widget.layout = widgets.Layout(overflow='hidden')\n",
    "    qgrid_widget._update_df()\n",
    "    # Display the widget\n",
    "    clear_output()\n",
    "    print(\"Data files reviewed on: \", datetime.now().strftime(\"%A %d/%m/%y %H:%M\"))\n",
    "    display(button_box_rev)\n",
    "    display(qgrid_widget)\n",
    "\n",
    "def display_pandas_table_rev(button):\n",
    "    clear_output()\n",
    "    print(\"Data files reviewed on: \", datetime.now().strftime(\"%A %d/%m/%y %H:%M\"))\n",
    "    display(button_box_rev)\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    display(df_without_path_key)\n",
    "\n",
    "# Create buttons\n",
    "button_qgrid_rev = widgets.Button(description=\"Qgrid Checklist\", layout=widgets.Layout(width='250px'))\n",
    "button_pandas_rev = widgets.Button(description=\"Pandas Checklist\", layout=widgets.Layout(width='250px'))\n",
    "\n",
    "# Connect buttons to functions\n",
    "button_qgrid_rev.on_click(display_qgrid_table_rev)\n",
    "button_pandas_rev.on_click(display_pandas_table_rev)\n",
    "\n",
    "# Create a horizontal box with your buttons\n",
    "button_box_rev = widgets.HBox([button_qgrid_rev, button_pandas_rev])\n",
    "\n",
    "# Display the box\n",
    "display(button_box_rev)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3444ba9c",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## Link Experiment Data and Instrument Parameters  \n",
    "Experimental data from the user-submitted csv/xlsx files are matched to qPCR instrument parameters that are extracted from a .txt export file.\n",
    "- Matching to instrument parameters is presently only supported for ABI Quant Studio software.\n",
    "- Users of non-ABI instruments can still analyse data without instrument parameters being recorded (see ProxiPal manual)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed4903c",
   "metadata": {
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Column names of interest\n",
    "columns_of_interest = ['filepath_txt', 'Kit_#', 'InstrumentType', 'ExperimentRunStartTime',\n",
    "                       'QuantificationCycleMethod', 'Stage/CyclewhereAnalysisisperformed',\n",
    "                       'Chemistry', 'PassiveReference', 'BlockType', 'InstrumentSerialNumber']\n",
    "\n",
    "# Create input text field\n",
    "style = {'description_width': 'initial'}\n",
    "input_text = widgets.IntText(description='Select experiment index to analyze:', value=9999, style=style)\n",
    "\n",
    "# Create a button\n",
    "button_params = widgets.Button(description='Link CSV & EDS data',\n",
    "                               layout=widgets.Layout(width='250px'))\n",
    "\n",
    "# Define your function\n",
    "def pandas_link_params(path_key):\n",
    "    # Assuming the function ProxiPal.create_data_metatable is already defined\n",
    "    meta_list = create_data_metatable(eds2txt_match_dict, eds2csv_match_dict, path_key)\n",
    "\n",
    "    # Calibration columns\n",
    "    original_calibration_columns = ['CalibrationBackgroundisexpired', 'CalibrationPureDyeROXisexpired',\n",
    "                                   'CalibrationPureDyeSYBRisexpired', 'CalibrationRNasePisexpired',\n",
    "                                   'CalibrationROIisexpired', 'CalibrationUniformityisexpired']\n",
    "\n",
    "    # Check for presence of calibration columns in meta_list[0]\n",
    "    calibration_columns = []\n",
    "    missing_columns = []\n",
    "    for col in original_calibration_columns:\n",
    "        if col in meta_list[0].columns:\n",
    "            calibration_columns.append(col)\n",
    "        else:\n",
    "            missing_columns.append(col)\n",
    "\n",
    "    # Print missing calibration columns\n",
    "    if missing_columns:\n",
    "        print(\"Calibration standard: \", ', '.join(missing_columns), \" is not available.\")\n",
    "\n",
    "    # Initialize a new DataFrame\n",
    "    new_df = pd.DataFrame(columns=['Parameter', 'Status'])\n",
    "\n",
    "    # Populate the new DataFrame\n",
    "    for col in columns_of_interest:\n",
    "        if col in meta_list[0].columns:\n",
    "            unique_values = meta_list[0][col].dropna().unique()  # Get unique values excluding NaNs\n",
    "            unique_values_str = ', '.join(map(str, unique_values))  # Convert to string and join with commas\n",
    "            new_row = pd.DataFrame({'Parameter': [col], 'Status': [unique_values_str]})\n",
    "            new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
    "        else:\n",
    "            print(f\"Column '{col}' not found in the DataFrame.\")\n",
    "\n",
    "    # Calibration check\n",
    "    calibration_status = []\n",
    "    for col in calibration_columns:\n",
    "        if (meta_list[0][col] != 'No').any():  # If any value in the column is not 'No'\n",
    "            calibration_status.append(col.replace('Calibration', '').replace('isexpired', ''))\n",
    "    if len(calibration_status) == 0:\n",
    "        new_row = pd.DataFrame({'Parameter': ['Calibration Check'], 'Status': ['OK']})\n",
    "        new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
    "    else:\n",
    "        status_str = ', '.join(calibration_status)\n",
    "        new_row = pd.DataFrame({'Parameter': ['Calibration Check'],\n",
    "                                'Status': ['Calibration expired: ' + status_str]})\n",
    "        new_df = pd.concat([new_df, new_row], ignore_index=True)\n",
    "\n",
    "    display(new_df.style.set_properties(subset=['Status'], **{'width': '650px'}))\n",
    "\n",
    "\n",
    "# Define what happens when the button is clicked\n",
    "def button_link_params(b):\n",
    "    # Disable the button\n",
    "    button_params.disabled = True\n",
    "    # Fetch the path_key from df_pivot based on input_text value\n",
    "    path_key = df_pivot.at[input_text.value, 'path_key']\n",
    "    pandas_link_params(path_key)\n",
    "    print(\"CSV & EDS Link Complete:\", datetime.now().strftime(\"%A %d/%m/%y %H:%M\"))\n",
    "\n",
    "# Set the on_button_clicked function to be called when the button is clicked\n",
    "button_params.on_click(button_link_params)\n",
    "\n",
    "# Create a horizontal box with the text field and the button\n",
    "hbox = widgets.HBox([input_text, button_params])\n",
    "\n",
    "# Display the horizontal box\n",
    "display(hbox)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22ffc16",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## Show Experiment Plan  \n",
    "Experiment plans are extracted from the user-submitted csv/xlsx planning template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac45fbf1",
   "metadata": {
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def show_plan(button):\n",
    "    # Disable the button\n",
    "    button_plan.disabled = True\n",
    "    \n",
    "    #     Use the input_text value from the previous cell\n",
    "    input = input_text.value\n",
    "    exports_path = Path(data_folder / df_pivot['experiment'][input] / df_pivot['analysis'][input] / \"exports\")\n",
    "    metatable = pd.read_csv(exports_path / \"metatable.csv\")\n",
    "\n",
    "    unique_values = metatable[\"experiment_plan\"].unique().tolist()\n",
    "    list_of_strings = [f\"{i+1}. {value}\" for i, value in enumerate(unique_values[0].split('\\n'))]\n",
    "\n",
    "    display(Markdown('\\n'.join(list_of_strings)))\n",
    "\n",
    "button_plan = widgets.Button(description=\"Show Experiment Plans\", layout=widgets.Layout(width='250px'))\n",
    "button_plan.on_click(show_plan)\n",
    "display(button_plan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2758c46",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def show_plate(button):\n",
    "    # Disable the button\n",
    "    button_plate.disabled = True\n",
    "    \n",
    "    #     Use the input_text value from the previous cell\n",
    "    input = input_text.value\n",
    "    exports_path = Path(data_folder / df_pivot['experiment'][input] / df_pivot['analysis'][input] / \"exports\")\n",
    "    metatable = pd.read_csv(exports_path / \"metatable.csv\")\n",
    "    \n",
    "    fig1 = create_plate_visualization(metatable, palette = None, font_size = 14)\n",
    "    plt.close('all')\n",
    "    plt.figure(fig1)\n",
    "    plt.show()\n",
    "\n",
    "button_plate = widgets.Button(description=\"Show Plate Plan\", layout=widgets.Layout(width='250px'))\n",
    "button_plate.on_click(show_plate)\n",
    "display(button_plate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e88ea80",
   "metadata": {},
   "source": [
    "## Plate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdcc8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v1 = 'ct'\n",
    "# v2 = 'SLR; log10(x); exc_std0; rdml_log2N0 (mean eff) - no plateau - stat efficiency; raw_ng/L'\n",
    "# v3 = 'rdml_indiv PCR eff'\n",
    "\n",
    "# plot_metatable = py_metatable.copy()\n",
    "# plot_metatable[v1] = pd.to_numeric(plot_metatable[v1], errors='coerce').round(1)\n",
    "# plot_metatable[v2] = pd.to_numeric(plot_metatable[v2], errors='coerce').round(0).astype(int)\n",
    "# plot_metatable[v3] = pd.to_numeric(plot_metatable[v3], errors='coerce').round(2)\n",
    "\n",
    "# fig2 = create_plate_visualization(plot_metatable, plate_format= 96, palette = None, font_size = 9,\n",
    "#                                    value1=(v1, 'ct: '), \n",
    "#                                    value2=(v2, 'ng/L: '),\n",
    "#                                   heatmap=True, heatmap_palette=\"vlag\", heatmap_value=(v3, 'eff: '))\n",
    "# plt.close('all')\n",
    "# plt.figure(fig2)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d71640d",
   "metadata": {},
   "source": [
    "## Show Amplification and Melt Curve Plots  \n",
    "Reaction plots are best viewed in the qPCR instrument software but users can display them here by exporting to the experiment folder; \"Amplification Plot.jpg\" and \"Melt Curve Plot.jpg\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddea6e3",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def display_jpegs(button):\n",
    "    # Disable the button\n",
    "    button_jpegs.disabled = True\n",
    "    \n",
    "    input = input_text.value\n",
    "    experiment_folder = Path(data_folder / df_pivot['experiment'][input] / df_pivot['analysis'][input])\n",
    "    amp_plot = experiment_folder / 'Amplification Plot.jpg'\n",
    "    melt_plot = experiment_folder / 'Melt Curve Plot.jpg'\n",
    "    \n",
    "    if amp_plot.is_file():\n",
    "        display(Image(filename=amp_plot))\n",
    "    else:\n",
    "        print(\"Amplification Plot.jpg not found!\")\n",
    "\n",
    "    if melt_plot.is_file():\n",
    "        display(Image(filename=melt_plot))\n",
    "    else:\n",
    "        print(\"Melt Curve Plot.jpg not found!\")\n",
    "        \n",
    "    print(\"Plots displayed on: \", datetime.now().strftime(\"%A %d/%m/%y %H:%M\"))\n",
    "\n",
    "# Create a button\n",
    "button_jpegs = widgets.Button(description=\"Display qPCR Plots\", layout=widgets.Layout(width='250px'))\n",
    "\n",
    "# Assign the function to the button's on_click event\n",
    "button_jpegs.on_click(display_jpegs)\n",
    "\n",
    "# Display the button\n",
    "display(button_jpegs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3367709",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## Calculate Concentrations  \n",
    "This section applies python methods from the numpy, pandas, scikit-learn, plotly and rdmlpython packages. ProxiPal will check the experiment folder for any available .rdml exports and also process these using Ruijter's efficiency-corrected LinRegPCR approach.\n",
    "\n",
    "Calculations do not modify user-submitted files, and all calculated tables are saved to the relevant __/exports__ folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ce7118",
   "metadata": {},
   "source": [
    "### Quantitate with Simple Linear Regression  (Ct & rdml_Cq)\n",
    "The NFL IC-PLA qPCR demonstrates excellent linearity and parallelism with respect to NfL concentration. For this reason qPCR standards of quantitation can be reliably applied. Our default quantitation model is the most conventional and processes experimental data using user-defined instrument \"Ct\" values and, if available, log2-transformed LinReg \"N0\" values. Neither of these cycling statistics feature PCR efficiency-correction.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01bd135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a second button\n",
    "button_lin_reg = widgets.Button(description='Apply Linear Regression',\n",
    "                         layout=widgets.Layout(width='250px'))\n",
    "# Define the function to run when the second button is clicked\n",
    "def apply_lin_reg(b):\n",
    "    # Disable the button\n",
    "    button_lin_reg.disabled = True\n",
    "    \n",
    "#   Use the input_text value from the previous cell\n",
    "    input = input_text.value\n",
    "    path = Path(data_folder / df_pivot['experiment'][input] / df_pivot['analysis'][input] / \"exports\" / \"metatable.csv\")\n",
    "    metatable = pd.read_csv(path)\n",
    "    py_metatable = create_py_metatable(metatable, threshold_type='ct', rdml_check=True, export=True)\n",
    "    print(\"Standards calculated: \", datetime.now().strftime(\"%A %d/%m/%y %H:%M\"))\n",
    "# Set the on_button2_clicked function to be called when the second button is clicked\n",
    "button_lin_reg.on_click(apply_lin_reg)\n",
    "# Display the second button\n",
    "display(button_lin_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0db860",
   "metadata": {},
   "source": [
    "### Conventional Ct Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a959746a",
   "metadata": {},
   "source": [
    "#### Display Standards  \n",
    "Automated calculations are prefixed with \"py_\" and all standard curve assignments should be made by users in the csv/xlsx tableson a per well basis.  \n",
    "- Users should assign consistent threshold value for all reactions when exporting Ct values; for ABI systems we use 0.1 with the SYBR assays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fba34c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a button\n",
    "button_show_standards = widgets.Button(description=\"Display Standards\", \n",
    "                        layout=widgets.Layout(width='250px'))\n",
    "\n",
    "def process_metatable_py(metatable_path):\n",
    "    from IPython.display import clear_output, display\n",
    "    \n",
    "    # Read the metatable directly\n",
    "    py_metatable = pd.read_csv(metatable_path, low_memory=False)\n",
    "    \n",
    "    # Clear any existing output\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    # Create and display the standards plot first\n",
    "    print(\"\\nStandards Plot:\")\n",
    "    plt.figure(figsize=(8, 6))  # Create figure explicitly\n",
    "    result = plot_slr_standards(metatable=py_metatable, \n",
    "                              threshold_type='ct',\n",
    "                              std0_status='exc_std0',\n",
    "                              figsize=(8, 6),\n",
    "                              separate_plots=False)\n",
    "    plt.show()  # Force plot display\n",
    "    \n",
    "    # Print a separator and header for the tables section\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\nStandards Tables:\")\n",
    "    \n",
    "    # Get filepath from metatable\n",
    "    filepath = py_metatable['filepath_csv'].unique().tolist()[0]\n",
    "    \n",
    "    # Get the experiment tables\n",
    "    SLR_experiment_tables = extract_experiment_tables(\n",
    "        df=py_metatable,\n",
    "        filepath_csv=filepath,  # Use filepath from metatable\n",
    "        quant_model='SLR',\n",
    "        threshold_type='ct',\n",
    "        transform_x='log10(x)',\n",
    "        std0_status='exc_std0',\n",
    "        sample_type = 'standards',\n",
    "        simple_headers=True\n",
    "    )\n",
    "    \n",
    "    # Display report tables for each standard\n",
    "    for key in SLR_experiment_tables.keys():\n",
    "        if 'report_table' in key:\n",
    "            print(f\"\\n{key}:\")\n",
    "            display(SLR_experiment_tables[key])\n",
    "\n",
    "def show_standards_py(event):\n",
    "    # Disable the button\n",
    "    button_show_standards.disabled = True\n",
    "    \n",
    "    # Construct the direct path to py_metatable.csv\n",
    "    metatable_path = Path(data_folder / df_pivot['experiment'][input_text.value] / \n",
    "                         df_pivot['analysis'][input_text.value] / \"exports\" / \"py_metatable.csv\")\n",
    "    \n",
    "    # Process the metatable\n",
    "    process_metatable_py(metatable_path)\n",
    "    print(\"\\nData displayed on: \", datetime.now().strftime(\"%A %d/%m/%y %H:%M\"))\n",
    "\n",
    "# Attach the function to the button\n",
    "button_show_standards.on_click(show_standards_py)\n",
    "\n",
    "# Display the button\n",
    "display(button_show_standards)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50023007",
   "metadata": {},
   "source": [
    "#### QC Performance  \n",
    "PLACEHOLDER: The QC calculations below are implemented into the jupyter report-only. They aren't currently recorded in the master data tables.  \n",
    "Nomenclature in fail raw_ng/L and fail mean_ng/L is well:ng/L:no. of stdev from expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0327e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the buttons\n",
    "button_pandas_samples = widgets.Button(description=\"Pandas QC Table\", layout=widgets.Layout(width='250px'))\n",
    "\n",
    "# Create the data dictionary\n",
    "qc_dict = {\n",
    "    'sample_id': ['NFL-LoQ', 'NFL-QC-L[6]', 'NFL-QC-M[19]', 'NFL-QC-H[91]'],\n",
    "    'mean': [2, 6, 19, 91],\n",
    "    'stdev': [0.34, 0.81, 2.19, 9.91],\n",
    "    'stdev_range=2': ['[1, 3]', '[4, 8]', '[15, 23]', '[71, 111]'],\n",
    "    'fail raw_ng/L': [None, None, None, None],\n",
    "    'fail mean_ng/L': [None, None, None, None],\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "qc_df = pd.DataFrame(qc_dict)\n",
    "\n",
    "def process_qc_data(qc_df, metatable_df):\n",
    "    \"\"\"\n",
    "    Process QC data and identify failures based on standard deviation ranges.\n",
    "    Uses mean values from qc_df to evaluate failures for both raw and mean ng/L values.\n",
    "    \n",
    "    Parameters:\n",
    "    qc_df (pd.DataFrame): DataFrame containing QC information\n",
    "    metatable_df (pd.DataFrame): DataFrame containing measurement data with dilution column\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Updated QC DataFrame with fail values\n",
    "    \"\"\"\n",
    "    # Create a copy of the input DataFrame to avoid modifying the original\n",
    "    qc_df = qc_df.copy()\n",
    "    \n",
    "    def parse_range(range_str):\n",
    "        \"\"\"Extract min and max values from range string '[min, max]'\"\"\"\n",
    "        return [float(x) for x in range_str.strip('[]').split(',')]\n",
    "    \n",
    "    def calculate_deviations(value, mean, std):\n",
    "        \"\"\"Calculate number of standard deviations from mean\"\"\"\n",
    "        return abs(value - mean) / std\n",
    "    \n",
    "    def check_failures(sample_data, mean_val, std_val, value_column):\n",
    "        \"\"\"Check for failures in a specific value column\"\"\"\n",
    "        fails = []\n",
    "        for pos_idx, pos_row in sample_data.iterrows():\n",
    "            value = pos_row[value_column]\n",
    "            position = pos_row['position']\n",
    "            \n",
    "            # Check if value is outside the acceptable range defined by mean Â± 2*std\n",
    "            if (value < (mean_val - 2*std_val)) or (value > (mean_val + 2*std_val)):\n",
    "                dev_calc = calculate_deviations(value, mean_val, std_val)\n",
    "                fail_str = f\"[{position};{value:.0f};{dev_calc:.2f}]\"\n",
    "                fails.append(fail_str)\n",
    "        return fails\n",
    "    \n",
    "    # Process each QC sample\n",
    "    for idx, row in qc_df.iterrows():\n",
    "        sample_id = row['sample_id']\n",
    "        mean_val = row['mean']\n",
    "        std_val = row['stdev']\n",
    "        \n",
    "        # Filter metatable for current sample_id and dilution\n",
    "        sample_data = metatable_df[\n",
    "            (metatable_df['sample_id'] == sample_id) & \n",
    "            (metatable_df['dilution'] == 10)\n",
    "        ]\n",
    "        \n",
    "        # Check raw values\n",
    "        raw_fails = check_failures(sample_data, mean_val, std_val, \n",
    "                                 'SLR; log10(x); exc_std0; ct; raw_ng/L')\n",
    "        if raw_fails:\n",
    "            qc_df.at[idx, 'fail raw_ng/L'] = '; '.join(raw_fails)\n",
    "            \n",
    "        # Check mean values\n",
    "        mean_fails = check_failures(sample_data, mean_val, std_val,\n",
    "                                  'SLR; log10(x); exc_std0; ct; mean_ng/L')\n",
    "        if mean_fails:\n",
    "            qc_df.at[idx, 'fail mean_ng/L'] = ', '.join(mean_fails)\n",
    "    \n",
    "    return qc_df\n",
    "\n",
    "# Define the data display function for Pandas QC Table\n",
    "def display_pandas_dataframe(event):\n",
    "    input_val = input_text.value\n",
    "    \n",
    "    # Clear previous output first\n",
    "    clear_output()\n",
    "    # Show buttons immediately\n",
    "    display(widgets.HBox([button_qgrid_samples, button_pandas_samples]))\n",
    "    \n",
    "    metatable_path = Path(data_folder / df_pivot['experiment'][input_text.value] / \n",
    "                         df_pivot['analysis'][input_text.value] / \"exports\" / \"py_metatable.csv\")\n",
    "    # Read the metatable directly and process it\n",
    "    py_metatable = pd.read_csv(metatable_path, low_memory=False)\n",
    "\n",
    "    updated_QC_df = process_qc_data(qc_df, py_metatable)\n",
    "    \n",
    "    pd.set_option('display.max_rows', None)\n",
    "    display(updated_QC_df)\n",
    "\n",
    "# Assign the event handlers to the buttons\n",
    "button_pandas_samples.on_click(display_pandas_dataframe)\n",
    "\n",
    "# Display the buttons\n",
    "display(widgets.HBox([button_pandas_samples]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2db057",
   "metadata": {},
   "source": [
    "#### Display Samples  \n",
    "Displays the sample report table generated during concentration calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9058ff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the buttons\n",
    "button_qgrid_samples = widgets.Button(description=\"Qgrid Sample Table\", layout=widgets.Layout(width='250px'))\n",
    "button_pandas_samples = widgets.Button(description=\"Pandas Sample Table\", layout=widgets.Layout(width='250px'))\n",
    "\n",
    "# Define the data display function for Qgrid Sample Table\n",
    "def process_and_display_dataframe(event):\n",
    "    input_val = input_text.value\n",
    "    \n",
    "    # Clear previous output first\n",
    "    clear_output()\n",
    "    # Show buttons immediately\n",
    "    display(widgets.HBox([button_qgrid_samples, button_pandas_samples]))\n",
    "    \n",
    "    metatable_path = Path(data_folder / df_pivot['experiment'][input_text.value] / \n",
    "                         df_pivot['analysis'][input_text.value] / \"exports\" / \"py_metatable.csv\")\n",
    "    # Read the metatable directly and process it\n",
    "    py_metatable = pd.read_csv(metatable_path, low_memory=False)\n",
    "    # Get filepath from metatable\n",
    "    filepath = py_metatable['filepath_csv'].unique().tolist()[0]\n",
    "    \n",
    "    result = extract_experiment_tables(df = py_metatable, \n",
    "                                     filepath_csv = filepath, \n",
    "                                     quant_model = 'SLR', \n",
    "                                     threshold_type = 'ct', \n",
    "                                     transform_x='log10(x)', \n",
    "                                     std0_status='exc_std0', \n",
    "                                     sample_type = 'samples', \n",
    "                                     simple_headers=True)\n",
    "    \n",
    "    display(qgrid.show_grid(result['sample_report_table'], show_toolbar=False))\n",
    "\n",
    "# Define the data display function for Pandas Sample Table\n",
    "def display_pandas_dataframe(event):\n",
    "    input_val = input_text.value\n",
    "    \n",
    "    # Clear previous output first\n",
    "    clear_output()\n",
    "    # Show buttons immediately\n",
    "    display(widgets.HBox([button_qgrid_samples, button_pandas_samples]))\n",
    "    \n",
    "    metatable_path = Path(data_folder / df_pivot['experiment'][input_text.value] / \n",
    "                         df_pivot['analysis'][input_text.value] / \"exports\" / \"py_metatable.csv\")\n",
    "    # Read the metatable directly and process it\n",
    "    py_metatable = pd.read_csv(metatable_path, low_memory=False)\n",
    "    # Get filepath from metatable\n",
    "    filepath = py_metatable['filepath_csv'].unique().tolist()[0]\n",
    "    \n",
    "    result = extract_experiment_tables(df = py_metatable, \n",
    "                                     filepath_csv = filepath, \n",
    "                                     quant_model = 'SLR', \n",
    "                                     threshold_type = 'ct', \n",
    "                                     transform_x='log10(x)', \n",
    "                                     std0_status='exc_std0', \n",
    "                                     sample_type = 'samples', \n",
    "                                     simple_headers=True)\n",
    "    \n",
    "    pd.set_option('display.max_rows', None)\n",
    "    display(result['sample_report_table'])\n",
    "\n",
    "# Assign the event handlers to the buttons\n",
    "button_qgrid_samples.on_click(process_and_display_dataframe)\n",
    "button_pandas_samples.on_click(display_pandas_dataframe)\n",
    "\n",
    "# Display the buttons\n",
    "display(widgets.HBox([button_qgrid_samples, button_pandas_samples]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f13cea",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "#### Display Well Table  \n",
    "Displays the a filtered version of the py_metatable table generated during concentration calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6ffd73",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create the buttons\n",
    "button_qgrid_wells = widgets.Button(description=\"Qgrid Well Table\", layout=widgets.Layout(width='250px'))\n",
    "button_pandas_wells = widgets.Button(description=\"Pandas Well Table\", layout=widgets.Layout(width='250px'))\n",
    "\n",
    "# Define the data display function for Qgrid Sample Table\n",
    "def process_and_display_dataframe(event):\n",
    "    input_val = input_text.value\n",
    "    \n",
    "    # Clear previous output first\n",
    "    clear_output()\n",
    "    # Show buttons immediately\n",
    "    display(widgets.HBox([button_qgrid_wells, button_pandas_wells]))\n",
    "    \n",
    "    metatable_path = Path(data_folder / df_pivot['experiment'][input_text.value] / \n",
    "                         df_pivot['analysis'][input_text.value] / \"exports\" / \"py_metatable.csv\")\n",
    "    # Read the metatable directly and process it\n",
    "    py_metatable = pd.read_csv(metatable_path, low_memory=False)\n",
    "    # Get filepath from metatable\n",
    "    filepath = py_metatable['filepath_csv'].unique().tolist()[0]\n",
    "    \n",
    "    result = extract_experiment_tables(df = py_metatable, \n",
    "                                     filepath_csv = filepath, \n",
    "                                     quant_model = 'SLR', \n",
    "                                     threshold_type = 'ct', \n",
    "                                     transform_x='log10(x)', \n",
    "                                     std0_status='exc_std0', \n",
    "                                     sample_type = 'wells', \n",
    "                                     simple_headers=True)\n",
    "    \n",
    "    display(qgrid.show_grid(result['wells_table'], show_toolbar=False))\n",
    "\n",
    "# Define the data display function for Pandas Sample Table\n",
    "def display_pandas_dataframe(event):\n",
    "    input_val = input_text.value\n",
    "    \n",
    "    # Clear previous output first\n",
    "    clear_output()\n",
    "    # Show buttons immediately\n",
    "    display(widgets.HBox([button_qgrid_wells, button_pandas_wells]))\n",
    "    \n",
    "    metatable_path = Path(data_folder / df_pivot['experiment'][input_text.value] / \n",
    "                         df_pivot['analysis'][input_text.value] / \"exports\" / \"py_metatable.csv\")\n",
    "    # Read the metatable directly and process it\n",
    "    py_metatable = pd.read_csv(metatable_path, low_memory=False)\n",
    "    # Get filepath from metatable\n",
    "    filepath = py_metatable['filepath_csv'].unique().tolist()[0]\n",
    "    \n",
    "    result = extract_experiment_tables(df = py_metatable, \n",
    "                                     filepath_csv = filepath, \n",
    "                                     quant_model = 'SLR', \n",
    "                                     threshold_type = 'ct', \n",
    "                                     transform_x='log10(x)', \n",
    "                                     std0_status='exc_std0', \n",
    "                                     sample_type = 'wells', \n",
    "                                     simple_headers=True)\n",
    "    \n",
    "    pd.set_option('display.max_rows', None)\n",
    "    display(result['wells_table'])\n",
    "\n",
    "# Assign the event handlers to the buttons\n",
    "button_qgrid_wells.on_click(process_and_display_dataframe)\n",
    "button_pandas_wells.on_click(display_pandas_dataframe)\n",
    "\n",
    "# Display the buttons\n",
    "display(widgets.HBox([button_qgrid_wells, button_pandas_wells]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c64735",
   "metadata": {},
   "source": [
    "### Amplication Efficiency Corrected Analyses Using LinReg/RDML  \n",
    "LinReg is used to adjust threshold values for variations in cycling efficiency among individual reactions. The implementation we use here is N0; however we do not draw simple linear regression between linear concentration and linear N0; instead we use log10(concentration) vs -1.log2(N0) which we find leads to slightly better standard curve fits.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3750441e",
   "metadata": {},
   "source": [
    "#### Display Standard Curves  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7dd988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a button\n",
    "button_show_RDMLstandards = widgets.Button(description=\"Display rdml_log2N0 Standards\", \n",
    "                        layout=widgets.Layout(width='250px'))\n",
    "\n",
    "def process_metatable_py(metatable_path):\n",
    "    from IPython.display import clear_output, display\n",
    "    \n",
    "    # Read the metatable directly\n",
    "    py_metatable = pd.read_csv(metatable_path, low_memory=False)\n",
    "    \n",
    "    # Clear any existing output\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    # Create and display the standards plot first\n",
    "    print(\"\\nStandards Plot:\")\n",
    "    plt.figure(figsize=(8, 6))  # Create figure explicitly\n",
    "    result = plot_slr_standards(metatable=py_metatable, \n",
    "                              threshold_type='rdml_log2N0 (mean eff) - no plateau - stat efficiency',\n",
    "                              std0_status='exc_std0',\n",
    "                              figsize=(8, 6),\n",
    "                              separate_plots=False)\n",
    "    plt.show()  # Force plot display\n",
    "    \n",
    "    # Print a separator and header for the tables section\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\nStandards Tables:\")\n",
    "    \n",
    "    # Get filepath from metatable\n",
    "    filepath = py_metatable['filepath_csv'].unique().tolist()[0]\n",
    "    \n",
    "    # Get the experiment tables\n",
    "    SLR_experiment_tables = extract_experiment_tables(\n",
    "        df=py_metatable,\n",
    "        filepath_csv=filepath,  # Use filepath from metatable\n",
    "        quant_model='SLR',\n",
    "        threshold_type='rdml_log2N0 (mean eff) - no plateau - stat efficiency',\n",
    "        transform_x='log10(x)',\n",
    "        std0_status='exc_std0',\n",
    "        sample_type = 'standards',\n",
    "        simple_headers=True\n",
    "    )\n",
    "    \n",
    "    # Display report tables for each standard\n",
    "    for key in SLR_experiment_tables.keys():\n",
    "        if 'report_table' in key:\n",
    "            print(f\"\\n{key}:\")\n",
    "            display(SLR_experiment_tables[key])\n",
    "\n",
    "def show_standards_py(event):\n",
    "    # Disable the button\n",
    "    button_show_RDMLstandards.disabled = True\n",
    "    \n",
    "    # Construct the direct path to py_metatable.csv\n",
    "    metatable_path = Path(data_folder / df_pivot['experiment'][input_text.value] / \n",
    "                         df_pivot['analysis'][input_text.value] / \"exports\" / \"py_metatable.csv\")\n",
    "    \n",
    "    # Process the metatable\n",
    "    process_metatable_py(metatable_path)\n",
    "    print(\"\\nData displayed on: \", datetime.now().strftime(\"%A %d/%m/%y %H:%M\"))\n",
    "\n",
    "# Attach the function to the button\n",
    "button_show_RDMLstandards.on_click(show_standards_py)\n",
    "\n",
    "# Display the button\n",
    "display(button_show_RDMLstandards)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac711ad",
   "metadata": {},
   "source": [
    "#### Display Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e8fec3",
   "metadata": {
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create the buttons\n",
    "button_qgrid_RDMLsamples = widgets.Button(description=\"Qgrid rdml_log2N0 Samples\", layout=widgets.Layout(width='250px'))\n",
    "button_pandas_RDMLsamples = widgets.Button(description=\"Pandas rdml_log2N0 Samples\", layout=widgets.Layout(width='250px'))\n",
    "\n",
    "# Define the data display function for Qgrid Sample Table\n",
    "def process_and_display_dataframe(event):\n",
    "    input_val = input_text.value\n",
    "    \n",
    "    # Clear previous output first\n",
    "    clear_output()\n",
    "    # Show buttons immediately\n",
    "    display(widgets.HBox([button_qgrid_RDMLsamples, button_pandas_RDMLsamples]))\n",
    "    \n",
    "    metatable_path = Path(data_folder / df_pivot['experiment'][input_text.value] / \n",
    "                         df_pivot['analysis'][input_text.value] / \"exports\" / \"py_metatable.csv\")\n",
    "    # Read the metatable directly and process it\n",
    "    py_metatable = pd.read_csv(metatable_path, low_memory=False)\n",
    "    # Get filepath from metatable\n",
    "    filepath = py_metatable['filepath_csv'].unique().tolist()[0]\n",
    "    \n",
    "    result = extract_experiment_tables(df = py_metatable, \n",
    "                                     filepath_csv = filepath, \n",
    "                                     quant_model = 'SLR', \n",
    "                                     threshold_type = 'rdml_log2N0 (mean eff) - no plateau - stat efficiency', \n",
    "                                     transform_x='log10(x)', \n",
    "                                     std0_status='exc_std0', \n",
    "                                     sample_type = 'samples', \n",
    "                                     simple_headers=True)\n",
    "    \n",
    "    display(qgrid.show_grid(result['sample_report_table'], show_toolbar=False))\n",
    "\n",
    "# Define the data display function for Pandas Sample Table\n",
    "def display_pandas_dataframe(event):\n",
    "    input_val = input_text.value\n",
    "    \n",
    "    # Clear previous output first\n",
    "    clear_output()\n",
    "    # Show buttons immediately\n",
    "    display(widgets.HBox([button_qgrid_RDMLsamples, button_pandas_RDMLsamples]))\n",
    "    \n",
    "    metatable_path = Path(data_folder / df_pivot['experiment'][input_text.value] / \n",
    "                         df_pivot['analysis'][input_text.value] / \"exports\" / \"py_metatable.csv\")\n",
    "    # Read the metatable directly and process it\n",
    "    py_metatable = pd.read_csv(metatable_path, low_memory=False)\n",
    "    # Get filepath from metatable\n",
    "    filepath = py_metatable['filepath_csv'].unique().tolist()[0]\n",
    "    \n",
    "    result = extract_experiment_tables(df = py_metatable, \n",
    "                                     filepath_csv = filepath, \n",
    "                                     quant_model = 'SLR', \n",
    "                                     threshold_type = 'rdml_log2N0 (mean eff) - no plateau - stat efficiency', \n",
    "                                     transform_x='log10(x)', \n",
    "                                     std0_status='exc_std0', \n",
    "                                     sample_type = 'samples', \n",
    "                                     simple_headers=True)\n",
    "    \n",
    "    pd.set_option('display.max_rows', None)\n",
    "    display(result['sample_report_table'])\n",
    "\n",
    "# Assign the event handlers to the buttons\n",
    "button_qgrid_RDMLsamples.on_click(process_and_display_dataframe)\n",
    "button_pandas_RDMLsamples.on_click(display_pandas_dataframe)\n",
    "\n",
    "# Display the buttons\n",
    "display(widgets.HBox([button_qgrid_RDMLsamples, button_pandas_RDMLsamples]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fcdab8",
   "metadata": {},
   "source": [
    "#### Display Wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ca02ca",
   "metadata": {
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create the buttons\n",
    "button_qgrid_RDMLwells = widgets.Button(description=\"Qgrid rdml_log2N0 Wells\", layout=widgets.Layout(width='250px'))\n",
    "button_pandas_RDMLwells = widgets.Button(description=\"Pandas rdml_log2N0 Wells\", layout=widgets.Layout(width='250px'))\n",
    "\n",
    "# Define the data display function for Qgrid Sample Table\n",
    "def process_and_display_dataframe(event):\n",
    "    input_val = input_text.value\n",
    "    \n",
    "    # Clear previous output first\n",
    "    clear_output()\n",
    "    # Show buttons immediately\n",
    "    display(widgets.HBox([button_qgrid_RDMLwells, button_pandas_RDMLwells]))\n",
    "    \n",
    "    metatable_path = Path(data_folder / df_pivot['experiment'][input_text.value] / \n",
    "                         df_pivot['analysis'][input_text.value] / \"exports\" / \"py_metatable.csv\")\n",
    "    # Read the metatable directly and process it\n",
    "    py_metatable = pd.read_csv(metatable_path, low_memory=False)\n",
    "    # Get filepath from metatable\n",
    "    filepath = py_metatable['filepath_csv'].unique().tolist()[0]\n",
    "    \n",
    "    result = extract_experiment_tables(df = py_metatable, \n",
    "                                     filepath_csv = filepath, \n",
    "                                     quant_model = 'SLR', \n",
    "                                     threshold_type = 'rdml_log2N0 (mean eff) - no plateau - stat efficiency', \n",
    "                                     transform_x='log10(x)', \n",
    "                                     std0_status='exc_std0', \n",
    "                                     sample_type = 'wells', \n",
    "                                     simple_headers=True)\n",
    "    \n",
    "    display(qgrid.show_grid(result['wells_table'], show_toolbar=False))\n",
    "\n",
    "# Define the data display function for Pandas Sample Table\n",
    "def display_pandas_dataframe(event):\n",
    "    input_val = input_text.value\n",
    "    \n",
    "    # Clear previous output first\n",
    "    clear_output()\n",
    "    # Show buttons immediately\n",
    "    display(widgets.HBox([button_qgrid_RDMLwells, button_pandas_RDMLwells]))\n",
    "    \n",
    "    metatable_path = Path(data_folder / df_pivot['experiment'][input_text.value] / \n",
    "                         df_pivot['analysis'][input_text.value] / \"exports\" / \"py_metatable.csv\")\n",
    "    # Read the metatable directly and process it\n",
    "    py_metatable = pd.read_csv(metatable_path, low_memory=False)\n",
    "    # Get filepath from metatable\n",
    "    filepath = py_metatable['filepath_csv'].unique().tolist()[0]\n",
    "    \n",
    "    result = extract_experiment_tables(df = py_metatable, \n",
    "                                     filepath_csv = filepath, \n",
    "                                     quant_model = 'SLR', \n",
    "                                     threshold_type = 'rdml_log2N0 (mean eff) - no plateau - stat efficiency', \n",
    "                                     transform_x='log10(x)', \n",
    "                                     std0_status='exc_std0', \n",
    "                                     sample_type = 'wells', \n",
    "                                     simple_headers=True)\n",
    "    \n",
    "    pd.set_option('display.max_rows', None)\n",
    "    display(result['wells_table'])\n",
    "\n",
    "# Assign the event handlers to the buttons\n",
    "button_qgrid_RDMLwells.on_click(process_and_display_dataframe)\n",
    "button_pandas_RDMLwells.on_click(display_pandas_dataframe)\n",
    "\n",
    "# Display the buttons\n",
    "display(widgets.HBox([button_qgrid_RDMLwells, button_pandas_RDMLwells]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc3da7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plate optics\n",
    "\n",
    "# at moment instr data is added to the mastertable note the metatable.\n",
    "# can check prepcr rox\n",
    "# prepcr sybr\n",
    "# and delta of the two\n",
    "# move this section to the end\n",
    "\n",
    "# df_rox = summarise_signal(py_metatable, 'rox', 'rox (eds; multicomponent data)', cycles=(0,30))\n",
    "# df_rox[['rox_30','rox_mean_30', 'rox_stdev_30']].head()\n",
    "\n",
    "# put on the heatmap plate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d542f7",
   "metadata": {},
   "source": [
    "# Advanced Processing  \n",
    "The current standard report lets users compare the performance of simple linear regressions performed with user-set thresholds in MS excel, python, and automated threshold selection with efficiency correction using linreg rdml. In advanced processing we test 3 quantitative models; simple linear regression (qPCR convention), 4-parameter logistic and 5 parameter logistic (immunoassay convention). All three models are fitted to all threshold types, with or without background subtraction, including \"Ct\", \"rdml_Cq\", \"rdml_log2N0\" and \"rdml_N0\" using both mean-corrected and individually-corrected efficiencies.  The result is produces concentration calculations and statistical reporting for 96 different models and combinations. This is quite computationally intensive and substantially increases the size of each experiment's *py_metatable.csv*.  \n",
    "  \n",
    "The advantage of doing this is to 1) test imprecision performance of all models, and 2) to identify the best fit for new targets in PLA development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf101b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a second button\n",
    "button_calc_all_models = widgets.Button(description='Calculate All Models',\n",
    "                         layout=widgets.Layout(width='250px'))\n",
    "# Define the function to run when the second button is clicked\n",
    "def apply_all_models(b):\n",
    "    # Disable the button\n",
    "    button_calc_all_models.disabled = True\n",
    "    \n",
    "#   Use the input_text value from the previous cell\n",
    "    input = input_text.value\n",
    "    path = Path(data_folder / df_pivot['experiment'][input] / df_pivot['analysis'][input] / \"exports\" / \"metatable.csv\")\n",
    "    metatable = pd.read_csv(path)\n",
    "    py_metatable = calc_py_metatable_all_models(metatable, rdml_check=True, export=True)\n",
    "\n",
    "# Set the on_button2_clicked function to be called when the second button is clicked\n",
    "button_calc_all_models.on_click(apply_all_models)\n",
    "# Display the second button\n",
    "display(button_calc_all_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a062dd",
   "metadata": {},
   "source": [
    "# Protected Queries: Current Experiment\n",
    "These queries require use of the Master Table, a database built from the __/Data__, __/Samples__, and __/Quality folders__. For privacy reasons __/Samples__ and __/Quality__ information is password protected (default = _admin_).  \n",
    "\n",
    "## Link Sample Submissions    \n",
    "Matches sample submission information for the current experiment report, (_i.e. specimen type, collection type, medical abbreviation, age, gender_) from the __/Samples__ folder with the experiment data selected in step 1.2  \n",
    "* Does not generate new megatables or mastertables  \n",
    "* Sample-linked data is saved to __/user_downloads__ to accommodate folder permissions (if put in __/data__ sample info. would be leaked).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6648d69d",
   "metadata": {
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Link_Sample_Processor:\n",
    "    def __init__(self):\n",
    "        self.qgrid_widget = None\n",
    "        self.master_table_filtered_grouped = None\n",
    "        self.password = proxipal_password\n",
    "\n",
    "    def load_and_filter_master(self, button):\n",
    "        \n",
    "        \n",
    "        if self.password_input.value != self.password:\n",
    "            print('Incorrect password. Try again.')\n",
    "            return\n",
    "        clear_output()\n",
    "        display(button_box_link)\n",
    "        \n",
    "        master_table = load_most_recent_mastertable(base_path / 'exports')[0]\n",
    "        \n",
    "        mean_ng_col = 'SLR; log10(x); exc_std0; rdml_log2N0 (mean eff) - no plateau - stat efficiency; mean_ng/L'\n",
    "        \n",
    "        # define columns to round\n",
    "        numeric_columns = [mean_ng_col, 'age']\n",
    "        # Process numeric columns\n",
    "        for col in numeric_columns:\n",
    "            master_table[col] = pd.to_numeric(master_table[col], errors='coerce')\\\n",
    "                .round(0)\\\n",
    "                .fillna(-999)\\\n",
    "                .astype(int)\\\n",
    "                .replace(-999, 'na')\n",
    "        \n",
    "        path_query = df_pivot['path_key'][input_text.value] + '.csv'\n",
    "        # filter for select columns\n",
    "#         master_table_filtered = master_table[master_table['filepath_csv']==path_query][['sample_id', 'tube_id', 'target', 'py_mean_ng/L', 'med_abbrev', 'age', 'sex', 'specimen_type', 'collection_type']].fillna('na')\n",
    "        master_table_filtered = master_table[master_table['filepath_csv']==path_query][['sample_id', 'tube_id', 'target', \n",
    "                                                                                         mean_ng_col,\n",
    "                                                                                        'med_abbrev', 'age', 'sex', 'specimen_type', 'collection_type', 'comments (anyone can use)']].fillna('na')\n",
    "        \n",
    "        # filter out usr_ignore == 1\n",
    "        master_table_filtered = master_table_filtered[master_table['usr_ignore'] != 1]\n",
    "        # filter out regular expressions used for standards\n",
    "        master_table_filtered = master_table_filtered[~master_table['sample_id'].str.contains(r'\\[(.*?)\\]_', regex=True, na=False)]\n",
    "        # rename mean_ng/L column for simple header\n",
    "        master_table_filtered = master_table_filtered.rename(columns={mean_ng_col: 'mean_ng/L'})\n",
    "\n",
    "        def custom_collapse(s):\n",
    "            if s.nunique() == 1:\n",
    "                return s.iloc[0]\n",
    "            else:\n",
    "                return '/'.join(s.astype(str).unique())\n",
    "\n",
    "        self.master_table_filtered_grouped = master_table_filtered.groupby(['sample_id', 'tube_id']).agg(custom_collapse).reset_index()\n",
    "        \n",
    "        global recent_master_table_string        \n",
    "        recent_master_table_string = str(load_most_recent_mastertable(base_path / 'exports')[1])\n",
    "        print(\"ProxiPal master table retrieved: \" + recent_master_table_string)\n",
    "        print(\"\"\"Default mean_ng/L = 'SLR; log10(x); exc_std0; rdml_log2N0 (mean eff) - no plateau - stat efficiency; mean_ng/L'\n",
    "        To change mean_ng/L model, change the Jupyter code cell directly\")\"\"\")\n",
    "        \n",
    "    def display_qgrid_link(self, button):\n",
    "        # Clear previous output\n",
    "        clear_output()\n",
    "        print(\"ProxiPal master table retrieved: \" + recent_master_table_string)\n",
    "        \n",
    "        # Disable the button\n",
    "        if self.master_table_filtered_grouped is None:\n",
    "            print('Please load and filter the master table first.')\n",
    "            return\n",
    "        # Get a list of the column names\n",
    "        col_names = self.master_table_filtered_grouped.columns.tolist()\n",
    "\n",
    "        # Define column definitions for qgrid\n",
    "        col_defs = {\n",
    "            'index': {'width': 100 / 15},\n",
    "            'sample_id': {'width': 100 / 0.75},\n",
    "            'target': {'width': 100 / 7},\n",
    "            'age': {'width': 100 / 15},\n",
    "            'sex': {'width': 100 / 15}\n",
    "        }\n",
    "        # Add the rest of the columns with a width of 100/4\n",
    "        for col in col_names:\n",
    "            if col not in col_defs:\n",
    "                col_defs[col] = {'width': 100}\n",
    "\n",
    "        # Set the maxVisibleRows to the length of the collapsed_df\n",
    "        grid_options = {\n",
    "            'maxVisibleRows': 42\n",
    "        }\n",
    "\n",
    "        # Add the grid_options parameter to the qgrid.show_grid function\n",
    "        self.qgrid_widget = qgrid.show_grid(self.master_table_filtered_grouped, show_toolbar=False, column_definitions=col_defs, grid_options=grid_options)         \n",
    "        display(button_box_link)\n",
    "        display(self.qgrid_widget)\n",
    "    \n",
    "    def display_pandas_link(self, button):\n",
    "        # Clear previous output\n",
    "        clear_output()\n",
    "        print(\"ProxiPal master table retrieved: \" + recent_master_table_string)\n",
    "        \n",
    "        # Disable the button\n",
    "        if self.master_table_filtered_grouped is None:\n",
    "            print('Please load and filter the master table first.')\n",
    "            return\n",
    "\n",
    "        # Clear previous output and display pandas table\n",
    "        pd.set_option('display.max_rows', None)\n",
    "        display(button_box_link)\n",
    "        display(self.master_table_filtered_grouped)\n",
    "\n",
    "    def export_link(self, button):\n",
    "        if self.master_table_filtered_grouped is None:\n",
    "            print('Please load and filter the master table first.')\n",
    "            return\n",
    "\n",
    "        # Write the header\n",
    "        export_name = user_downloads / 'SampleLinkedData.csv'\n",
    "        with open(export_name, 'w') as f:\n",
    "            f.write(df_pivot['path_key'][input_text.value] + '   ' + datetime.now().strftime(\"%A %d/%m/%y %H:%M\") + '\\n')\n",
    "        self.master_table_filtered_grouped.to_csv(export_name, mode='a', index=False)  # mode='a' means append\n",
    "        print('CSV table exported to: ' + str(export_name))\n",
    "\n",
    "Link_processor = Link_Sample_Processor()\n",
    "\n",
    "# Password input\n",
    "Link_processor.password_input = widgets.Password(description='Password')\n",
    "\n",
    "# Original buttons\n",
    "button_qgrid_link = widgets.Button(description=\"Qgrid Link Table\", layout=widgets.Layout(width='250px'))\n",
    "button_qgrid_link.on_click(Link_processor.display_qgrid_link)\n",
    "\n",
    "button_pandas_link = widgets.Button(description=\"Pandas Link Table\", layout=widgets.Layout(width='250px'))\n",
    "button_pandas_link.on_click(Link_processor.display_pandas_link)\n",
    "\n",
    "button_export_link = widgets.Button(description=\"Export to CSV\", layout=widgets.Layout(width='250px'))\n",
    "button_export_link.on_click(Link_processor.export_link)\n",
    "\n",
    "button_load_master = widgets.Button(description=\"Filter Master Table\", layout=widgets.Layout(width='250px'))\n",
    "button_load_master.on_click(Link_processor.load_and_filter_master)\n",
    "\n",
    "# Create a horizontal box with your buttons\n",
    "button_box_link = widgets.HBox([Link_processor.password_input, button_load_master, button_qgrid_link, button_pandas_link, button_export_link])\n",
    "\n",
    "# Display the box\n",
    "display(button_box_link)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bdb5b7",
   "metadata": {},
   "source": [
    "## Link Quality Control Information  \n",
    "Quality monitoring currently uses a different system. It may be integrated here at a later date. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921306b7",
   "metadata": {},
   "source": [
    "# Protected Queries: Global Query  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff0a719",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## Batch All Experiments\n",
    "ProxiPal processes every available experiments in the /data folder and merges experimental data into a single .csv table that is exported to the /data/exports folder. _NB:This function will overwrite all previous ProxiPal reports._ \n",
    "* Every experiment in /data will be processed. This can take up to 10 minutes.  \n",
    "* A _data_megatable.csv_ will be created.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ff57de",
   "metadata": {
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "class BatchProcessor:\n",
    "    def __init__(self):\n",
    "        self.password = proxipal_password\n",
    "        \n",
    "    def batch_process_all(self, button):\n",
    "        # Disable the button\n",
    "        button.disabled = True\n",
    "        clear_output()\n",
    "        display(widgets_box_batch)\n",
    "        \n",
    "        password_input = self.password_input.value\n",
    "        slice_input = self.slice_input.value.strip()  # Remove any whitespace\n",
    "        \n",
    "        if password_input == self.password:\n",
    "            # Set df_pivot_slice based on input\n",
    "            df_pivot_slice = slice_input if slice_input else None\n",
    "            \n",
    "            # batch py_metatables with slice parameter\n",
    "            batch_py_metatables(eds2txt_match_dict, eds2csv_match_dict, df_pivot_slice=df_pivot_slice)\n",
    "            \n",
    "            # create data_megatable\n",
    "            data_megatable = create_data_megatable(data_folder)\n",
    "            print(\"New data_megatable.csv created: \", str(data_folder) + '/exports')\n",
    "            \n",
    "        else:\n",
    "            print('Incorrect password. Try again.')\n",
    "\n",
    "# Create an instance of the BatchProcessor class\n",
    "batch_processor = BatchProcessor()\n",
    "\n",
    "# Create password widget\n",
    "batch_processor.password_input = widgets.Password(\n",
    "    description='Password',\n",
    "    layout=widgets.Layout(width='275px')\n",
    ")\n",
    "\n",
    "# Create slice input widget\n",
    "batch_processor.slice_input = widgets.Text(\n",
    "    description='Slice:',\n",
    "    placeholder='e.g., 15:18 or 15:',\n",
    "    layout=widgets.Layout(width='275px')\n",
    ")\n",
    "\n",
    "# Create button widget\n",
    "button_batch_processor = widgets.Button(\n",
    "    description='Batch',\n",
    "    layout=widgets.Layout(width='250px')\n",
    ")\n",
    "\n",
    "# Execute function when button is clicked\n",
    "button_batch_processor.on_click(batch_processor.batch_process_all)\n",
    "\n",
    "# Create a vertical box for input widgets and a horizontal box for the final layout\n",
    "input_box = widgets.VBox([\n",
    "    batch_processor.password_input,\n",
    "    batch_processor.slice_input\n",
    "])\n",
    "\n",
    "# Create a horizontal box with your widgets\n",
    "widgets_box_batch = widgets.HBox([input_box, button_batch_processor])\n",
    "\n",
    "# Display the box\n",
    "display(widgets_box_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf6db95",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "## Identify Missing Sample Information   \n",
    "Creates a new master table from current __/Data__ and __/Samples__ folders. Searches the master table for instances of \"orphan\" entries:  \n",
    "__\"data(+) submission(-)\":__ We have data, but no submission info.  \n",
    "__\"data(-) submission(+)\":__ We have submission info, but no data.  \n",
    "  \n",
    "To ensure the most recent data is used.  \n",
    "* A new _data_megatable.csv_ will be created.  \n",
    "* A new _samples_megatable.csv_ will be created.  \n",
    "* A new _'MissingSampleInfo.csv'_ is exportable on request.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ca43e8",
   "metadata": {
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Orphan_Processor:\n",
    "    def __init__(self):\n",
    "        self.master_dict = None\n",
    "        self.password = proxipal_password\n",
    "\n",
    "    def create_new_master_table(self, button):\n",
    "        password_input = self.password_input.value\n",
    "        if password_input == self.password:\n",
    "            clear_output()\n",
    "            display(widgets_box_orphan)\n",
    "            \n",
    "            # create data_megatable\n",
    "            data_megatable = create_data_megatable(data_folder)\n",
    "\n",
    "            # create samples_megatable\n",
    "            samples_megatable = create_samples_megatable(samples_folder, export=True)\n",
    "\n",
    "            # create_master_table\n",
    "            self.master_dict = create_master_table(match_type='TS')\n",
    "\n",
    "            print(\"New Master Table created with Data and Sample Info: \", datetime.now().strftime(\"%A %d/%m/%y %H:%M\"))\n",
    "        \n",
    "        else:\n",
    "            print('Incorrect password. Try again.')            \n",
    "            \n",
    "    def qgrid_orphan(self, button):\n",
    "        clear_output()\n",
    "        display(widgets_box_orphan)\n",
    "\n",
    "        # Get a list of the column names\n",
    "        col_names = self.master_dict['master_df_orphan'].columns.tolist()\n",
    "\n",
    "        # Define column definitions for qgrid\n",
    "        col_defs = {'index': {'width': 100 / 15}}\n",
    "        for col in col_names:\n",
    "            if col not in col_defs:\n",
    "                col_defs[col] = {'width': 100}\n",
    "\n",
    "        # Set the maxVisibleRows to the length of the collapsed_df\n",
    "        grid_options = {'maxVisibleRows': 30}\n",
    "\n",
    "        # Add the grid_options parameter to the qgrid.show_grid function\n",
    "        qgrid_widget = qgrid.show_grid(self.master_dict['master_df_orphan'], show_toolbar=False, column_definitions=col_defs, grid_options=grid_options)\n",
    "        display(qgrid_widget)\n",
    "\n",
    "\n",
    "    def pandas_orphan(self, button):\n",
    "        clear_output()\n",
    "        display(widgets_box_orphan)\n",
    "        display(self.master_dict['master_df_orphan'])\n",
    "    \n",
    "    def csv_orphan(self, button):\n",
    "        export_name = user_downloads / 'MissingSampleInfo.csv'\n",
    "        with open(export_name, 'w') as f:\n",
    "            f.write('Missing Sample Info' + '   ' + datetime.now().strftime(\"%A %d/%m/%y %H:%M\") + '\\n')\n",
    "\n",
    "        self.master_dict['master_df_orphan'].to_csv(export_name, mode='a', index=False)  # mode='a' means append\n",
    "        print('CSV table exported to: ' + str(export_name))\n",
    "\n",
    "orphan_processor = Orphan_Processor()\n",
    "\n",
    "# Password input\n",
    "# processor.password_input = widgets.Password(description='Password')\n",
    "orphan_processor.password_input = widgets.Password(description='Password')\n",
    "\n",
    "\n",
    "# Create buttons\n",
    "button_qgrid_orphan = widgets.Button(description='Qgrid Orphan Table', layout=widgets.Layout(width='250px'))\n",
    "button_pandas_orphan = widgets.Button(description=\"Pandas Orphan Table\", layout=widgets.Layout(width='250px'))\n",
    "button_export_orphan = widgets.Button(description=\"Export to CSV\", layout=widgets.Layout(width='250px'))\n",
    "button_create_master = widgets.Button(description=\"Create Master Table\", layout=widgets.Layout(width='250px'))\n",
    "\n",
    "# Connect buttons to functions\n",
    "button_qgrid_orphan.on_click(orphan_processor.qgrid_orphan)\n",
    "button_pandas_orphan.on_click(orphan_processor.pandas_orphan)\n",
    "button_export_orphan.on_click(orphan_processor.csv_orphan)\n",
    "# button_create_master.on_click(Orphan_Processor.create_new_master_table)\n",
    "button_create_master.on_click(orphan_processor.create_new_master_table)\n",
    "\n",
    "# Create a horizontal box with your buttons\n",
    "widgets_box_orphan = widgets.HBox([orphan_processor.password_input, button_create_master, button_qgrid_orphan, button_pandas_orphan, button_export_orphan])\n",
    "\n",
    "# Display the box\n",
    "display(widgets_box_orphan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e8b14f",
   "metadata": {},
   "source": [
    "## Create Master Table  \n",
    "Collates all ProxiPal reports and sample submissions. Cross-checks all submitted sample IDs against all experimental data and matches all entries against a 1 row per reaction \"master table\" that contains all available data.  \n",
    "* A _data_megatable.csv_ will be created  \n",
    "* A _samples_megatable.csv_ will be created  \n",
    "* A _mastertable.csv_ will be created  \n",
    "* An _orphans table_ will be displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad711a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MasterTable_Processor:\n",
    "    def __init__(self):\n",
    "        self.password = proxipal_password\n",
    "\n",
    "    def batch_process_all(self, button):\n",
    "        # Disable the button\n",
    "        button.disabled = True\n",
    "\n",
    "        clear_output()\n",
    "        display(widgets_box_master)\n",
    "\n",
    "        password_input = self.password_input.value\n",
    "        if password_input == self.password:\n",
    "            # create data_megatable\n",
    "            data_megatable = create_data_megatable(data_folder)\n",
    "            print(\"New data_megatable.csv created: \", str(data_folder) + '/exports')\n",
    "\n",
    "            # create samples_megatable\n",
    "            samples_megatable = create_samples_megatable(samples_folder, export=True)\n",
    "            print(\"New samples_megatable.csv created: \", str(samples_folder) + '/exports')\n",
    "\n",
    "            # create_master_table\n",
    "            master_dict = create_master_table(match_type='TS')\n",
    "\n",
    "            print(\"New mastertable.csv created: \", str(base_path) + '/exports')\n",
    "            print(\"Samples without Data or Submission info are shown in the table below\")\n",
    "\n",
    "            # Get a list of the column names\n",
    "            col_names = master_dict['master_df_orphan'].columns.tolist()\n",
    "\n",
    "            # Define column definitions for qgrid\n",
    "            col_defs = {'index': {'width': 100 / 15}}\n",
    "            for col in col_names:\n",
    "                if col not in col_defs:\n",
    "                    col_defs[col] = {'width': 100}\n",
    "\n",
    "            # Set the maxVisibleRows to the length of the collapsed_df\n",
    "            grid_options = {'maxVisibleRows': 30}\n",
    "\n",
    "            # Add the grid_options parameter to the qgrid.show_grid function\n",
    "            qgrid_widget = qgrid.show_grid(master_dict['master_df_orphan'], show_toolbar=False, column_definitions=col_defs, grid_options=grid_options)\n",
    "            display(qgrid_widget)\n",
    "        else:\n",
    "            print('Incorrect password. Try again.')\n",
    "\n",
    "# Create an instance of the MasterTable_Processor class\n",
    "master_processor = MasterTable_Processor()\n",
    "\n",
    "# Create password widget\n",
    "master_processor.password_input = widgets.Password(description='Password', layout=widgets.Layout(width='275px'))\n",
    "\n",
    "# Create button widget\n",
    "button_master_processor = widgets.Button(description='Create Master', layout=widgets.Layout(width='250px'))\n",
    "\n",
    "# Execute function when button is clicked\n",
    "button_master_processor.on_click(master_processor.batch_process_all)\n",
    "\n",
    "# Create a horizontal box with your widgets\n",
    "widgets_box_master = widgets.HBox([master_processor.password_input, button_master_processor])\n",
    "\n",
    "# Display the box\n",
    "display(widgets_box_master)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ec735b",
   "metadata": {},
   "source": [
    "## Add Raw Instrument Data to Master Table  \n",
    "Will extract all raw data from every quantstudio exported .txt file and merge the data for every individual reaction to the most recent master table in the database. Raw instrument data includes 'Raw Data', 'Amplification Data', 'Multicomponent Data', and 'Melt Curve Raw Data'.  \n",
    "* An existing _mastertable.csv_ is loaded  \n",
    "* A _mastertable_wInstrumentData.csv_ is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3887d07e",
   "metadata": {
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Batch_Instr_Processor:\n",
    "    def __init__(self):\n",
    "        self.password = proxipal_password\n",
    "\n",
    "    def batch_process_all(self, button):\n",
    "        # Disable the button\n",
    "        button.disabled = True\n",
    "\n",
    "        clear_output()\n",
    "        display(widgets_box_batch_instr)\n",
    "\n",
    "        password_input = self.password_input.value\n",
    "        if password_input == self.password:\n",
    "            # Check for an eds > txt export\n",
    "            eds2txt_match_list, eds2txt_match_dict = find_matched_filenames(data_folder, read_export = True)\n",
    "            \n",
    "            # Check for a csv file with the same name as the eds file\n",
    "            eds2csv_match_list, eds2csv_match_dict = find_matched_filenames(data_folder, native_format = '.eds', export_format = '.csv', read_export = True)\n",
    "            \n",
    "            # Review matched filenames\n",
    "            df_pivot = review_matched_filenames(eds2txt_match_dict, eds2csv_match_dict)\n",
    "            \n",
    "            # Extract raw values from all .eds exports into one table\n",
    "            master_instr_df = build_master_instr_df(df_pivot, data_folder)\n",
    "            \n",
    "            # Load mastertable\n",
    "            mastertable, mastertable_file = load_most_recent_mastertable(base_path / 'exports')\n",
    "            \n",
    "            # Merge with the master table\n",
    "            mastertable_expanded = pd.merge(mastertable, master_instr_df, how='inner', on=['well', 'filepath_txt'])\n",
    "                \n",
    "            curr_time = datetime.now().strftime(\"%Y%m%d %H-%M\")[2:].replace(' ', '_T')\n",
    "            \n",
    "            filename = curr_time + ' mastertable_wInstrumentData.csv'     \n",
    "                                            \n",
    "            # Save the table to /python folder for future use.\n",
    "            mastertable_expanded.to_csv(Path(base_path / 'exports' / filename))\n",
    "\n",
    "            print(\"Raw Instrument Data added to Master Table:\", filename, ' ', datetime.now().strftime(\"%A %d/%m/%y %H:%M\"))\n",
    "\n",
    "\n",
    "        else:\n",
    "            print('Incorrect password. Try again.')\n",
    "\n",
    "# Create an instance of the BatchProcessor class\n",
    "batch_instr_processor = Batch_Instr_Processor()\n",
    "\n",
    "# Create password widget\n",
    "batch_instr_processor.password_input = widgets.Password(description='Password', layout=widgets.Layout(width='275px'))\n",
    "\n",
    "# Create button widget\n",
    "button_batch_instr_processor = widgets.Button(description='Add All Instrument Data', layout=widgets.Layout(width='250px'))\n",
    "\n",
    "# Execute function when button is clicked\n",
    "button_batch_instr_processor.on_click(batch_instr_processor.batch_process_all)\n",
    "\n",
    "# Create a horizontal box with your widgets\n",
    "widgets_box_batch_instr = widgets.HBox([batch_instr_processor.password_input, button_batch_instr_processor])\n",
    "\n",
    "# # Display the box\n",
    "display(widgets_box_batch_instr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e032b2ed",
   "metadata": {},
   "source": [
    "# Export Report  \n",
    "Calculations from Section 1 can only be integrated into the Master Table by functions from Section 2.\n",
    "\n",
    "To revisit individual reports (or keep a record of analysis) without rerunning the notebook code:\n",
    "- Save a .ipynb copy of this report to the main folder of your chosen experiment.  \n",
    "- Save a html copy of this report to the main folder of your chosen experiment.  \n",
    "- The easiest way to save a html report _without code cells_ is to use a browser plugin like Save Page WE.\n",
    "\n",
    "<div style=\"font-size:14px; font-weight:bold; color:red\">For all tables to be exported properly, ensure you have displayed the non-interactive Pandas table</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
